{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFER LEARNING FOR IMAGE CLASSIFICATION OF COSTA RICAN DISHES USING RESNET50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for Image Classification with Transfer Learning using ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# transform for the train data\n",
    "# Define transformations for training data:\n",
    "# 1. RandomResizedCrop: Randomly crops and resizes images to 224x224 for consistency and data augmentation.\n",
    "# 2. RandomHorizontalFlip: Horizontally flips images randomly for augmentation.\n",
    "# 3. RandomRotation: Randomly rotates the images in a 15 degrees angle.\n",
    "# 4. ColorJitter: Adjusts brightness and contrast for variety in image appearance.\n",
    "# 5. ToTensor: Converts images to PyTorch tensors, the format required for model input.\n",
    "# 6. Normalize: Normalizes images to have a specific mean and standard deviation, aligning with pre-trained model expectations.\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=25),\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# transform for the validation data\n",
    "# Define transformations for validation data:\n",
    "# 1. Resize: Increases the size of the image to 256x256 pixels.\n",
    "# 2. CenterCrop: Crops the center part of the image to 224x224, ensuring it's the same size as the training images.\n",
    "# 3. ToTensor: Converts the image to a PyTorch tensor, suitable for model input.\n",
    "# 4. Normalize: Normalizes the image with the specified mean and standard deviation, matching the training data's normalization.\n",
    "validation_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# load the datasets\n",
    "path_traning_data = \"../dataset/trainig-data\"\n",
    "path_validation_data = \"../dataset/test-data\"\n",
    "train_dataset = ImageFolder(root=path_traning_data, transform=train_transforms)\n",
    "validation_dataset = ImageFolder(root=path_validation_data, transform=validation_transforms)\n",
    "\n",
    "# define the data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# load the pre-trained ResNet50 model\n",
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Get the number of input features for the final fully connected layer of the pre-trained model\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "# Replace the final fully connected layer with a new one tailored to the number of classes in the dataset\n",
    "# This is necessary to adapt the pre-trained model for the specific classification task\n",
    "model.fc = torch.nn.Linear(num_ftrs, len(train_dataset.classes))\n",
    "\n",
    "# move the model to a GPU if it is available\n",
    "# Check and set the device for Apple M1 (MPS)\n",
    "#device = torch.device(\"cpu\")\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "#criterion = torch.nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# Define loss function and optimizer with increased weight decay for L2 regularization\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)  # Added weight decay\n",
    "\n",
    "# set numbers of epochs\n",
    "num_epochs= 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainig phase and validation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_losses = []\n",
    "validation_losses = []\n",
    "validation_accuracies = []\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    training_loss = 0.0\n",
    "\n",
    "    # Iterate over training data\n",
    "    for images, labels in train_loader:\n",
    "        # Move images and labels to the device (GPU or CPU)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Reset gradients for new iteration\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute model output\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate loss between output and true labels\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backpropagate the error and update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss over the batch\n",
    "        training_loss += loss.item() * images.size(0)\n",
    "\n",
    "    # Calculate average training loss for this epoch\n",
    "    training_loss = training_loss / len(train_loader.dataset)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    validation_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    # No gradient update during validation to reduce memory usage\n",
    "    with torch.no_grad():\n",
    "        # Iterate over validation data\n",
    "        for images, labels in validation_loader:\n",
    "\n",
    "            # Move images and labels to the device\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Compute model output\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Calculate validation loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            validation_loss += loss.item() * images.size(0)\n",
    "\n",
    "            # Calculate the number of correct predictions\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate average validation loss and accuracy for this epoch\n",
    "    validation_loss = validation_loss / len(validation_loader.dataset)\n",
    "    validation_accuracy = correct_predictions / len(validation_loader.dataset)\n",
    "\n",
    "    # Store losses and accuracy for plotting\n",
    "    training_losses.append(training_loss)\n",
    "    validation_losses.append(validation_loss)\n",
    "    validation_accuracies.append(validation_accuracy)\n",
    "\n",
    "    # Print epoch summary\n",
    "    print(f'Epoch: {epoch+1}/{num_epochs}, Training Loss: {training_loss:.4f}, Validation Loss: {validation_loss:.4f}, Validation Accuracy: {validation_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
